{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OK_Keras Dense_Spacy NLP_whiskey.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1nRTN3-3sPSedUAJQctpES-YyXio-7KRK",
      "authorship_tag": "ABX9TyOepxoGWvJuLYdwslW3OEEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bs3537/DS-Unit-4-Sprint-1-NLP/blob/master/OK_Keras_Dense_Spacy_NLP_whiskey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbQfKT-m4VHC",
        "colab_type": "code",
        "outputId": "c901c030-4fa1-465a-d92d-346332b46db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdNWE9rXV73F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#USING VECTORIZATION BY SPACY NLP AND KERAS SEQUENTIAL NEURAL NETWORK FOR TRAINING ON TRAIN DATA AND MAKING PREDICTIONS\n",
        "#DATASET: WHISKY RATINGS CLASSIFICATION FROM REVIEWS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ie3lEXJuAHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/bs3537/DS-Unit-4-Sprint-1-NLP/master/module3-document-classification/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoH7Cj9QuHyj",
        "colab_type": "code",
        "outputId": "2623bb42-ceb3-4fb7-c922-21f95d2819bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "train.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1321</td>\n",
              "      <td>\\nSometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only) A$133</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ... ratingCategory\n",
              "0  1321  ...  1            \n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W9YaF4afe0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text'] = train['description'].str.strip('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWyxaPv0g-kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train2 = train.drop(columns=['description', 'id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8bIkK0Bhe43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train3 = train2.rename(columns={\"ratingCategory\": \"label\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSgVNpfjhz_a",
        "colab_type": "code",
        "outputId": "1486f64b-4fba-4984-a878-543873134a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "train3.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Sometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only) A$133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text\n",
              "0  1      Sometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only) A$133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_HOYPjT40fT",
        "colab_type": "code",
        "outputId": "9ac46b37-0d2c-402f-85f8-42c68564247c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_trn, df_val = train_test_split(train3, stratify = train3['label'], test_size = 0.20, random_state=42)\n",
        "\n",
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3269, 2), (818, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6hASHtIDF7C",
        "colab_type": "code",
        "outputId": "bc3e92ec-325d-4f27-c39c-46712491a2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "#Vectorize text using spacy\n",
        "pip install -U spacy[cuda92]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy[cuda92] in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: cupy-cuda92>=5.0.0b4; extra == \"cuda92\" in /usr/local/lib/python3.6/dist-packages (from spacy[cuda92]) (8.0.0b1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[cuda92]) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda92]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda92>=5.0.0b4; extra == \"cuda92\"->spacy[cuda92]) (0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda92]) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_H3hENEaD7",
        "colab_type": "code",
        "outputId": "d40bdf70-e716-4573-8ffb-d4f3207bf7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "!python3 -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lDr61VmEAVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqiSGk4TFYuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"NLP is awesome!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyUObbIVFcCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oZSSRclFfA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_trn['text']\n",
        "Y = df_trn['label']\n",
        "X_spacy = get_word_vectors(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz0cdXPIJPzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.DataFrame(X_spacy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1YrmxtvJbJL",
        "colab_type": "code",
        "outputId": "47cdae4d-0f0a-4bab-e304-ad8dbb3f1a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "X_train.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.045203</td>\n",
              "      <td>0.225353</td>\n",
              "      <td>-0.122706</td>\n",
              "      <td>-0.091795</td>\n",
              "      <td>0.05775</td>\n",
              "      <td>0.15319</td>\n",
              "      <td>-0.109985</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>-0.040869</td>\n",
              "      <td>1.68712</td>\n",
              "      <td>-0.112916</td>\n",
              "      <td>0.052514</td>\n",
              "      <td>-0.097823</td>\n",
              "      <td>-0.108442</td>\n",
              "      <td>-0.096102</td>\n",
              "      <td>-0.150793</td>\n",
              "      <td>-0.020358</td>\n",
              "      <td>1.114478</td>\n",
              "      <td>-0.122863</td>\n",
              "      <td>-0.077131</td>\n",
              "      <td>-0.012964</td>\n",
              "      <td>0.062064</td>\n",
              "      <td>0.015005</td>\n",
              "      <td>-0.013178</td>\n",
              "      <td>-0.032395</td>\n",
              "      <td>-0.082518</td>\n",
              "      <td>0.064337</td>\n",
              "      <td>0.004904</td>\n",
              "      <td>0.116789</td>\n",
              "      <td>-0.303146</td>\n",
              "      <td>-0.009842</td>\n",
              "      <td>0.048855</td>\n",
              "      <td>-0.085829</td>\n",
              "      <td>-0.082199</td>\n",
              "      <td>0.124694</td>\n",
              "      <td>-0.039435</td>\n",
              "      <td>0.018605</td>\n",
              "      <td>0.034327</td>\n",
              "      <td>-0.041166</td>\n",
              "      <td>0.073664</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065737</td>\n",
              "      <td>0.009891</td>\n",
              "      <td>0.081973</td>\n",
              "      <td>0.13168</td>\n",
              "      <td>0.019332</td>\n",
              "      <td>-0.078192</td>\n",
              "      <td>-0.103022</td>\n",
              "      <td>-0.050914</td>\n",
              "      <td>0.001833</td>\n",
              "      <td>0.028097</td>\n",
              "      <td>-0.071538</td>\n",
              "      <td>0.00272</td>\n",
              "      <td>0.008438</td>\n",
              "      <td>-0.24002</td>\n",
              "      <td>-0.284457</td>\n",
              "      <td>0.052573</td>\n",
              "      <td>-0.018513</td>\n",
              "      <td>0.143768</td>\n",
              "      <td>0.010605</td>\n",
              "      <td>0.31638</td>\n",
              "      <td>0.269419</td>\n",
              "      <td>-0.016737</td>\n",
              "      <td>0.10023</td>\n",
              "      <td>-0.154745</td>\n",
              "      <td>-0.076715</td>\n",
              "      <td>0.047223</td>\n",
              "      <td>0.257837</td>\n",
              "      <td>-0.070267</td>\n",
              "      <td>0.178728</td>\n",
              "      <td>-0.107351</td>\n",
              "      <td>-0.166363</td>\n",
              "      <td>0.092161</td>\n",
              "      <td>-0.091461</td>\n",
              "      <td>-0.096295</td>\n",
              "      <td>-0.231899</td>\n",
              "      <td>0.051272</td>\n",
              "      <td>0.09972</td>\n",
              "      <td>-0.21434</td>\n",
              "      <td>-0.110883</td>\n",
              "      <td>0.056796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...      296      297       298       299\n",
              "0 -0.045203  0.225353 -0.122706 -0.091795  ...  0.09972 -0.21434 -0.110883  0.056796\n",
              "\n",
              "[1 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT31e62eJ9SO",
        "colab_type": "code",
        "outputId": "cceb60f7-a0bd-4ec4-c1fa-c8cf8620fd4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1782    1\n",
              "3414    1\n",
              "2744    0\n",
              "77      1\n",
              "354     1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShZYiTBeKcWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train= pd.DataFrame(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaIzZh9IK6Z1",
        "colab_type": "code",
        "outputId": "d31d2f21-1ca4-497f-9ad3-fe9dc0ee85f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "Y_train.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label\n",
              "1782  1    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf7weL6sGB3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keras model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBfJk-43GSsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDDnJKvlG4Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for tensorflow 2.0, use tf.keras rather than keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLLaZ47jGAox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras import optimizers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzawZUW9HrhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWyPfA11H3GF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stacking layers on model, from keras documentation\n",
        "\n",
        "model.add(Dense(16, activation='relu', input_dim=X_train.shape[1])) #earlier 16 was units = 10\n",
        "model.add(Dropout(0.2)) #Dropout is a regularization technique in Keras #https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/ #prevents overfitting,\n",
        "#Droput = 0.2 is OK for smaller NNs, 0.5 for bigger models,\n",
        "model.add(Dense(1, activation='sigmoid')) #no of units = no. or columns in y train, earlier 1 was units = 1\n",
        "\n",
        "#use sigmoid rather than softmax activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpL1cICTITmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bb4CUAYISJF",
        "colab_type": "code",
        "outputId": "d15953b6-78ce-4ede-e5cd-794e240861dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#from keras.callbacks import EarlyStopping\n",
        "optimizer = tf.keras.optimizers.Adam(lr= 0.001) #default learning rate for keras, works well for most NN tasks. \n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy'])\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "# can use early stopping funtion here\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 16)                4816      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 4,833\n",
            "Trainable params: 4,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKgyjt7eJ19A",
        "colab_type": "code",
        "outputId": "0143157b-1ad5-4daa-b625-b5f8a7bee512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3269, 300), (3269, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzyURDhmMeg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Val. data\n",
        "\n",
        "X_val = df_val['text']\n",
        "Y_val = df_val['label']\n",
        "X_val_spacy = get_word_vectors(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBufyRw5M4_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val2 = pd.DataFrame(X_val_spacy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF5kGaIOM_8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_val2= pd.DataFrame(Y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bGD8eGJNRFU",
        "colab_type": "code",
        "outputId": "16fef8eb-76c0-4f30-d947-e6ada86e2857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=24, verbose=True, validation_data=(X_val2, Y_val2), batch_size=10)\n",
        "\n",
        "#start with 100-200 epochs then tune after viewing the losses and accuracy plot\n",
        "#increasing batch size may increase accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.7963 - val_loss: 0.5501 - val_accuracy: 0.7372\n",
            "Epoch 2/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.7944 - val_loss: 0.5679 - val_accuracy: 0.7347\n",
            "Epoch 3/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8012 - val_loss: 0.5645 - val_accuracy: 0.7445\n",
            "Epoch 4/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.7859 - val_loss: 0.5564 - val_accuracy: 0.7347\n",
            "Epoch 5/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3908 - accuracy: 0.7871 - val_loss: 0.5580 - val_accuracy: 0.7359\n",
            "Epoch 6/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3799 - accuracy: 0.7947 - val_loss: 0.5535 - val_accuracy: 0.7372\n",
            "Epoch 7/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.7914 - val_loss: 0.5517 - val_accuracy: 0.7433\n",
            "Epoch 8/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.7917 - val_loss: 0.5630 - val_accuracy: 0.7384\n",
            "Epoch 9/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3835 - accuracy: 0.7938 - val_loss: 0.5609 - val_accuracy: 0.7408\n",
            "Epoch 10/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3824 - accuracy: 0.7947 - val_loss: 0.5733 - val_accuracy: 0.7421\n",
            "Epoch 11/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3866 - accuracy: 0.7849 - val_loss: 0.5771 - val_accuracy: 0.7286\n",
            "Epoch 12/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.7941 - val_loss: 0.5662 - val_accuracy: 0.7359\n",
            "Epoch 13/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8006 - val_loss: 0.5671 - val_accuracy: 0.7445\n",
            "Epoch 14/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.7963 - val_loss: 0.5934 - val_accuracy: 0.7408\n",
            "Epoch 15/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.7987 - val_loss: 0.5701 - val_accuracy: 0.7359\n",
            "Epoch 16/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3733 - accuracy: 0.7911 - val_loss: 0.5995 - val_accuracy: 0.7249\n",
            "Epoch 17/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3690 - accuracy: 0.7929 - val_loss: 0.6019 - val_accuracy: 0.7433\n",
            "Epoch 18/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3656 - accuracy: 0.7993 - val_loss: 0.6035 - val_accuracy: 0.7335\n",
            "Epoch 19/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.7963 - val_loss: 0.5861 - val_accuracy: 0.7298\n",
            "Epoch 20/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.7963 - val_loss: 0.5836 - val_accuracy: 0.7164\n",
            "Epoch 21/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.7947 - val_loss: 0.5785 - val_accuracy: 0.7408\n",
            "Epoch 22/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.7950 - val_loss: 0.5915 - val_accuracy: 0.7347\n",
            "Epoch 23/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3558 - accuracy: 0.7981 - val_loss: 0.6096 - val_accuracy: 0.7347\n",
            "Epoch 24/24\n",
            "327/327 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.7908 - val_loss: 0.5967 - val_accuracy: 0.7396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XAjZqFwNHaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Val loss increases after epoch 24, so can use that as cut off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q82o8ZdARRnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss, train_accuracy = model.evaluate(X_train, Y_train, verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Abvr0SsRcuU",
        "colab_type": "code",
        "outputId": "dedb3e59-f3d7-4586-bd95-e63478829503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Training Accuracy: {:.4f}\".format(train_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.8134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAjKyU0AP8ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_accuracy = model.evaluate(X_val2, Y_val2, verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFDBEIFkRm09",
        "colab_type": "code",
        "outputId": "73bafecd-1bd9-4b12-be21-37c71d124bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Validation Accuracy: {:.4f}\".format(val_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxPrLFHjP5iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hypertune by learning rate, no of epochs, batch size etc.\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}